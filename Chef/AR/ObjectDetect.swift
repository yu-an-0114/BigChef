import UIKit
import Vision
import CoreML
import ARKit
import Foundation

/// å–®ä¾‹ï¼Œç”¨æ–¼ 2D ç‰©ä»¶åµæ¸¬ä¸¦ç¹ªè£½åœ¨ overlayView ä¸Š
class ObjectDetector {
    static let shared = ObjectDetector()

    private weak var overlayView: UIView?
    private var boxLayers = [CAShapeLayer]()
    private var textLayers = [CATextLayer]()
    private let vnModel: VNCoreMLModel
    private(set) var latestDetection: DetectionSnapshot?

    private init() {
        do {
            let coreMLModel = try CookDetect(configuration: MLModelConfiguration()).model
            vnModel = try VNCoreMLModel(for: coreMLModel)
        } catch {
            fatalError("âŒ ç„¡æ³•è¼‰å…¥ CookDetect æ¨¡å‹ï¼š\(error)")
        }
    }

    struct DetectionSnapshot {
        let rectInView: CGRect
        let normalizedRect: CGRect
        let identifier: String
        let confidence: Float
        let timestamp: Date
    }

    struct NotificationKeys {
        static let rect = "ObjectDetector.rect"
        static let normalizedRect = "ObjectDetector.normalizedRect"
        static let identifier = "ObjectDetector.identifier"
        static let confidence = "ObjectDetector.confidence"
    }

    /// è¨­å®šç”¨æ–¼ç¹ªè£½åµæ¸¬çµæœçš„ Overlay
    func configure(overlay: UIView) {
        overlayView = overlay
    }

    /// æ¸…é™¤æ‰€æœ‰èˆŠçš„ç¹ªè£½ Layer
    func clear() {
        boxLayers.forEach { $0.removeFromSuperlayer() }
        textLayers.forEach { $0.removeFromSuperlayer() }
        boxLayers.removeAll()
        textLayers.removeAll()
    }

    /// åµæ¸¬æŒ‡å®šå®¹å™¨ï¼Œå›å‚³ (boundingRect, label, confidence) æˆ– nil
    func detectContainer(target container: Container,
                         in pixelBuffer: CVPixelBuffer,
                         completion: @escaping ((CGRect, String, Float)?) -> Void)
    {
        let request = VNCoreMLRequest(model: vnModel) { [weak self] request, error in
            guard let self = self else { completion(nil); return }
            if let error = error {
                print("ğŸ›‘ VNCoreMLRequest éŒ¯èª¤ï¼š\(error)")
                completion(nil)
                return
            }

            // åªå–ç¬¬ä¸€å€‹ç¬¦åˆ container label çš„åµæ¸¬çµæœ
            let observations = (request.results as? [VNRecognizedObjectObservation]) ?? []
            for obs in observations {
                guard let top = obs.labels.first,
                      top.identifier == container.rawValue,
                      self.overlayView != nil
                else { continue }

                let box = obs.boundingBox

                DispatchQueue.main.async {
                    guard let overlay = self.overlayView else { completion(nil); return }
                    self.clear()
                    // ä»¥ä¸»åŸ·è¡Œç·’å®‰å…¨å­˜å– overlay.bounds ä¸¦æ›ç®— viewRect
                    let viewW = overlay.bounds.width
                    let viewH = overlay.bounds.height
                    let x = box.minX * viewW
                    let w = box.width * viewW
                    let y = (1 - box.maxY) * viewH  // Vision åº§æ¨™è½‰ UIKit
                    let h = box.height * viewH
                    let viewRect = CGRect(x: x, y: y, width: w, height: h)
                    let normalizedRect: CGRect
                    if viewW > 0, viewH > 0 {
                        normalizedRect = CGRect(
                            x: viewRect.origin.x / viewW,
                            y: viewRect.origin.y / viewH,
                            width: viewRect.width / viewW,
                            height: viewRect.height / viewH
                        )
                    } else {
                        normalizedRect = viewRect
                    }

                    let snapshot = DetectionSnapshot(
                        rectInView: viewRect,
                        normalizedRect: normalizedRect,
                        identifier: top.identifier,
                        confidence: top.confidence,
                        timestamp: Date()
                    )
                    self.latestDetection = snapshot

                    NotificationCenter.default.post(
                        name: .objectDetectorDidDetectContainer,
                        object: self,
                        userInfo: [
                            NotificationKeys.rect: NSValue(cgRect: viewRect),
                            NotificationKeys.normalizedRect: NSValue(cgRect: normalizedRect),
                            NotificationKeys.identifier: top.identifier,
                            NotificationKeys.confidence: NSNumber(value: top.confidence)
                        ]
                    )

                    // ï¼ˆä¿æŒç¹ªè£½ç¨‹å¼ç¢¼ç‚ºè¨»è§£ï¼Œåƒ…è¨ˆç®— rectï¼‰
                    /*
                    // 1. Bounding boxï¼ˆè‹¥æœªä¾†è¦é¡¯ç¤ºå¯è§£é™¤è¨»è§£ï¼‰
                    // ...
                    // 2. Label + confidenceï¼ˆè‹¥æœªä¾†è¦é¡¯ç¤ºå¯è§£é™¤è¨»è§£ï¼‰
                    // ...
                    */
                    
                    // å›å‚³ç•«åœ¨ overlay åº§æ¨™ç³»ä¸­çš„çŸ©å½¢
                    completion((viewRect, top.identifier, top.confidence))
                }
                return
            }

            // æ²’åµæ¸¬åˆ°
            completion(nil)
        }

        // è¨˜å¾—å¸¶ä¸Š orientation æ‰ä¸æœƒå› ç‚ºç•«é¢æ—‹è½‰å°è‡´æ¡†ä¸å°é½Š
        let handler = VNImageRequestHandler(
            cvPixelBuffer: pixelBuffer,
            orientation: .right,  // æˆ–æ ¹æ“šä½ çš„ ARView ç•«é¢æ–¹å‘èª¿æ•´
            options: [:]
        )
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
            } catch {
                print("ğŸ›‘ VNImageRequestHandler éŒ¯èª¤ï¼š\(error)")
                completion(nil)
                
            }
        }
    }
}

extension Notification.Name {
    static let objectDetectorDidDetectContainer = Notification.Name("ObjectDetectorDidDetectContainer")
}
